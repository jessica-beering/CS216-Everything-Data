{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting newspaper3k\n",
      "Collecting beautifulsoup4>=4.4.1 (from newspaper3k)\n",
      "  Using cached https://files.pythonhosted.org/packages/9e/d4/10f46e5cfac773e22707237bfcd51bbffeaf0a576b0a847ec7ab15bd7ace/beautifulsoup4-4.6.0-py3-none-any.whl\n",
      "Collecting feedfinder2>=0.0.4 (from newspaper3k)\n",
      "Collecting lxml>=3.6.0 (from newspaper3k)\n",
      "  Using cached https://files.pythonhosted.org/packages/30/65/6dcc7a1a0ec3bbc10a1316b3610f9997ca132183a5f5345c5b88fc1eaf79/lxml-4.2.1-cp35-cp35m-manylinux1_x86_64.whl\n",
      "Collecting nltk>=3.2.1 (from newspaper3k)\n",
      "Collecting tldextract>=2.0.1 (from newspaper3k)\n",
      "  Using cached https://files.pythonhosted.org/packages/0e/0c/1b7332684dfc2e6311d59cd00859a5318a7e0ba50334ad217ceb9555e213/tldextract-2.2.0-py2.py3-none-any.whl\n",
      "Collecting jieba3k>=0.35.1 (from newspaper3k)\n",
      "Collecting feedparser>=5.2.1 (from newspaper3k)\n",
      "Collecting PyYAML>=3.11 (from newspaper3k)\n",
      "Collecting requests>=2.10.0 (from newspaper3k)\n",
      "  Using cached https://files.pythonhosted.org/packages/49/df/50aa1999ab9bde74656c2919d9c0c085fd2b3775fd3eca826012bef76d8c/requests-2.18.4-py2.py3-none-any.whl\n",
      "Collecting Pillow>=3.3.0 (from newspaper3k)\n",
      "  Using cached https://files.pythonhosted.org/packages/07/52/8e27b9c54cb70d379244771a58483928b3a02db3c657d466ed84eb18f22b/Pillow-5.1.0-cp35-cp35m-manylinux1_x86_64.whl\n",
      "Collecting cssselect>=0.9.2 (from newspaper3k)\n",
      "  Using cached https://files.pythonhosted.org/packages/7b/44/25b7283e50585f0b4156960691d951b05d061abf4a714078393e51929b30/cssselect-1.0.3-py2.py3-none-any.whl\n",
      "Collecting python-dateutil>=2.5.3 (from newspaper3k)\n",
      "  Using cached https://files.pythonhosted.org/packages/0c/57/19f3a65bcf6d5be570ee8c35a5398496e10a0ddcbc95393b2d17f86aaaf8/python_dateutil-2.7.2-py2.py3-none-any.whl\n",
      "Collecting six (from feedfinder2>=0.0.4->newspaper3k)\n",
      "  Using cached https://files.pythonhosted.org/packages/67/4b/141a581104b1f6397bfa78ac9d43d8ad29a7ca43ea90a2d863fe3056e86a/six-1.11.0-py2.py3-none-any.whl\n",
      "Collecting setuptools (from tldextract>=2.0.1->newspaper3k)\n",
      "  Using cached https://files.pythonhosted.org/packages/20/d7/04a0b689d3035143e2ff288f4b9ee4bf6ed80585cc121c90bfd85a1a8c2e/setuptools-39.0.1-py2.py3-none-any.whl\n",
      "Collecting requests-file>=1.4 (from tldextract>=2.0.1->newspaper3k)\n",
      "  Using cached https://files.pythonhosted.org/packages/23/9c/6e63c23c39e53d3df41c77a3d05a49a42c4e1383a6d2a5e3233161b89dbf/requests_file-1.4.3-py2.py3-none-any.whl\n",
      "Collecting idna (from tldextract>=2.0.1->newspaper3k)\n",
      "  Using cached https://files.pythonhosted.org/packages/27/cc/6dd9a3869f15c2edfab863b992838277279ce92663d334df9ecf5106f5c6/idna-2.6-py2.py3-none-any.whl\n",
      "Collecting urllib3<1.23,>=1.21.1 (from requests>=2.10.0->newspaper3k)\n",
      "  Using cached https://files.pythonhosted.org/packages/63/cb/6965947c13a94236f6d4b8223e21beb4d576dc72e8130bd7880f600839b8/urllib3-1.22-py2.py3-none-any.whl\n",
      "Collecting chardet<3.1.0,>=3.0.2 (from requests>=2.10.0->newspaper3k)\n",
      "  Using cached https://files.pythonhosted.org/packages/bc/a9/01ffebfb562e4274b6487b4bb1ddec7ca55ec7510b22e4c51f14098443b8/chardet-3.0.4-py2.py3-none-any.whl\n",
      "Collecting certifi>=2017.4.17 (from requests>=2.10.0->newspaper3k)\n",
      "  Using cached https://files.pythonhosted.org/packages/7c/e6/92ad559b7192d846975fc916b65f667c7b8c3a32bea7372340bfe9a15fa5/certifi-2018.4.16-py2.py3-none-any.whl\n",
      "Installing collected packages: beautifulsoup4, urllib3, idna, chardet, certifi, requests, six, feedfinder2, lxml, nltk, setuptools, requests-file, tldextract, jieba3k, feedparser, PyYAML, Pillow, cssselect, python-dateutil, newspaper3k\n",
      "Successfully installed Pillow-5.0.0 PyYAML-3.12 beautifulsoup4-4.6.0 certifi-2018.1.18 chardet-3.0.4 cssselect-1.0.3 feedfinder2-0.0.4 feedparser-5.2.1 idna-2.6 jieba3k-0.35.1 lxml-4.2.0 newspaper3k-0.2.6 nltk-3.2.5 python-dateutil-2.7.0 requests-2.18.4 requests-file-1.4.3 setuptools-39.0.1 six-1.11.0 tldextract-2.2.0 urllib3-1.22\n",
      "\u001b[33mYou are using pip version 8.1.1, however version 10.0.0 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n",
      "Collecting pandas\n",
      "  Using cached https://files.pythonhosted.org/packages/99/0a/37930bbee7a06bb5ce7e12f7970b29a17a49605d0b08a72dee7ab76135bb/pandas-0.22.0-cp35-cp35m-manylinux1_x86_64.whl\n",
      "Collecting pytz>=2011k (from pandas)\n",
      "  Using cached https://files.pythonhosted.org/packages/dc/83/15f7833b70d3e067ca91467ca245bae0f6fe56ddc7451aa0dc5606b120f2/pytz-2018.4-py2.py3-none-any.whl\n",
      "Collecting numpy>=1.9.0 (from pandas)\n",
      "  Using cached https://files.pythonhosted.org/packages/ea/31/991207e6234b46a1228be970735ead9d6f06a298917d6f718c5e32e835bb/numpy-1.14.2-cp35-cp35m-manylinux1_x86_64.whl\n",
      "Collecting python-dateutil>=2 (from pandas)\n",
      "  Using cached https://files.pythonhosted.org/packages/0c/57/19f3a65bcf6d5be570ee8c35a5398496e10a0ddcbc95393b2d17f86aaaf8/python_dateutil-2.7.2-py2.py3-none-any.whl\n",
      "Collecting six>=1.5 (from python-dateutil>=2->pandas)\n",
      "  Using cached https://files.pythonhosted.org/packages/67/4b/141a581104b1f6397bfa78ac9d43d8ad29a7ca43ea90a2d863fe3056e86a/six-1.11.0-py2.py3-none-any.whl\n",
      "Installing collected packages: pytz, numpy, six, python-dateutil, pandas\n",
      "Successfully installed numpy-1.14.2 pandas-0.22.0 python-dateutil-2.7.0 pytz-2018.3 six-1.11.0\n",
      "\u001b[33mYou are using pip version 8.1.1, however version 10.0.0 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n",
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100   657  100   657    0     0   2192      0 --:--:-- --:--:-- --:--:--  2190\n",
      "Downloading \"brown\"\n",
      "[nltk_data] Downloading package brown to /home/vcm/nltk_data...\n",
      "[nltk_data]   Package brown is already up-to-date!\n",
      "Downloading \"punkt\"\n",
      "[nltk_data] Downloading package punkt to /home/vcm/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "Downloading \"maxent_treebank_pos_tagger\"\n",
      "[nltk_data] Downloading package maxent_treebank_pos_tagger to\n",
      "[nltk_data]     /home/vcm/nltk_data...\n",
      "[nltk_data]   Package maxent_treebank_pos_tagger is already up-to-\n",
      "[nltk_data]       date!\n",
      "Downloading \"movie_reviews\"\n",
      "[nltk_data] Downloading package movie_reviews to\n",
      "[nltk_data]     /home/vcm/nltk_data...\n",
      "[nltk_data]   Package movie_reviews is already up-to-date!\n",
      "Downloading \"wordnet\"\n",
      "[nltk_data] Downloading package wordnet to /home/vcm/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "Downloading \"stopwords\"\n",
      "[nltk_data] Downloading package stopwords to /home/vcm/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "Finished.\n"
     ]
    }
   ],
   "source": [
    "!pip3 install newspaper3k\n",
    "!pip3 install pandas\n",
    "!curl https://raw.githubusercontent.com/codelucas/newspaper/master/download_corpora.py | python3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import random\n",
    "import collections\n",
    "import re\n",
    "import string\n",
    "import pandas as pd\n",
    "import numpy\n",
    "import math\n",
    "from newspaper import Article\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('OnlineNewsPopularity.csv', 'r') as csvfile:\n",
    "    reader = csv.reader(csvfile)\n",
    "    row = []\n",
    "    df = pd.read_csv(csvfile)\n",
    "    \n",
    "    #---putting Id's and url's into lists to iterate through\n",
    "    idCol = df.id #put id's in to a list\n",
    "    idNum = 0     #counter for ids\n",
    "    urlCol = df.url #put url's in to a list\n",
    "    urlNum = 0      #counter for urls\n",
    "   \n",
    "    #---loop through each row and look at its id, its url, and generate it content\n",
    "        #-then add that those three to a row to put into the new csv file\n",
    "    \n",
    "    addtoCSV = list()\n",
    "    header = list()\n",
    "    header.append(\"id\")\n",
    "    header.append(\"url\")\n",
    "    header.append(\"author\")\n",
    "    header.append(\"pub_date\")\n",
    "    header.append(\"title\")\n",
    "    header.append(\"content\")\n",
    "    addtoCSV.append(header)\n",
    "\n",
    "\n",
    "\n",
    "    for i in range(1,39632): #39631 url's\n",
    "        rowinCSV = list()\n",
    "        idd = idCol[idNum]\n",
    "        urll = urlCol[urlNum]\n",
    "        idNum+=1\n",
    "        urlNum+=1\n",
    "        rowinCSV.append(idd)\n",
    "        rowinCSV.append(urll)\n",
    "        \n",
    "        #---get article content and append\n",
    "        \n",
    "        article = Article(urll) #make article object\n",
    "        article.download()    \n",
    "        article.parse()\n",
    "        content = article.text #get the content\n",
    "        auth = article.authors\n",
    "        date = article.publish_date\n",
    "        titl = article.title\n",
    "        rowinCSV.append(auth)\n",
    "        rowinCSV.append(date)\n",
    "        rowinCSV.append(titl)\n",
    "        rowinCSV.append(content)\n",
    "        \n",
    "        #--add all this info as a row into CSV file\n",
    "        addtoCSV.append(rowinCSV)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('articleContent.csv', 'w') as myfile:\n",
    "        wr = csv.writer(myfile)\n",
    "        wr.writerows(addtoCSV)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
